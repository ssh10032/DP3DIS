{"lr-AdamW": 4.199850425520496e-06, "trainer/global_step": 3499, "_timestamp": 1692878678.9171588, "_runtime": 5740.590300798416, "_step": 147, "train_loss_ce": 2.614474058151245, "train_loss_mask": 1.955075979232788, "train_loss_dice": 5.207860946655273, "train_loss_ce_0": 2.7444019317626953, "train_loss_mask_0": 1.8404631614685059, "train_loss_dice_0": 5.190817356109619, "train_loss_ce_1": 3.6546924114227295, "train_loss_mask_1": 1.8470007181167603, "train_loss_dice_1": 5.211605072021484, "train_loss_ce_2": 2.0957536697387695, "train_loss_mask_2": 1.8265972137451172, "train_loss_dice_2": 5.206108093261719, "train_loss_ce_3": 1.9807814359664917, "train_loss_mask_3": 1.815131664276123, "train_loss_dice_3": 5.221922874450684, "train_loss_ce_4": 1.9141120910644531, "train_loss_mask_4": 1.8063476085662842, "train_loss_dice_4": 5.161271095275879, "train_loss_ce_5": 1.8153564929962158, "train_loss_mask_5": 1.8712888956069946, "train_loss_dice_5": 5.190448760986328, "train_loss_ce_6": 1.92529296875, "train_loss_mask_6": 1.8538999557495117, "train_loss_dice_6": 5.17268705368042, "train_loss_ce_7": 1.7282460927963257, "train_loss_mask_7": 1.890481948852539, "train_loss_dice_7": 5.167945861816406, "train_loss_ce_8": 1.8619368076324463, "train_loss_mask_8": 1.8737719058990479, "train_loss_dice_8": 5.172883987426758, "train_loss_ce_9": 1.855716347694397, "train_loss_mask_9": 1.846357822418213, "train_loss_dice_9": 5.150508880615234, "train_loss_ce_10": 1.8343480825424194, "train_loss_mask_10": 1.8788385391235352, "train_loss_dice_10": 5.210448265075684, "train_loss_ce_11": 1.8402278423309326, "train_loss_mask_11": 1.902775764465332, "train_loss_dice_11": 5.221992492675781, "train_mean_loss_ce": 2.1434876918792725, "train_mean_loss_mask": 1.8621562719345093, "train_mean_loss_dice": 5.191269397735596, "epoch": 8, "train_loss_mean": 110.69895935058594}